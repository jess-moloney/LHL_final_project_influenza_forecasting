{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_total.pkl\", \"rb\" ))\n",
    "df_flu_pre_COVID = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_pre_COVID_total.pkl\", \"rb\" ))\n",
    "df_flu_COVID = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_COVID_total.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surveillance Week</th>\n",
       "      <th>A(H1N1)pdm09</th>\n",
       "      <th>A(H3N2)</th>\n",
       "      <th>A(Unsubtyped)</th>\n",
       "      <th>Influenza B</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total Cases</th>\n",
       "      <th>Epiweek</th>\n",
       "      <th>Week Ending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9.0</td>\n",
       "      <td>201535</td>\n",
       "      <td>2015-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>18.0</td>\n",
       "      <td>201536</td>\n",
       "      <td>2015-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>15.0</td>\n",
       "      <td>201537</td>\n",
       "      <td>2015-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>29.0</td>\n",
       "      <td>201538</td>\n",
       "      <td>2015-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>59.0</td>\n",
       "      <td>201539</td>\n",
       "      <td>2015-10-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Surveillance Week  A(H1N1)pdm09  A(H3N2)  A(Unsubtyped)  Influenza B  Year  \\\n",
       "0                35           1.0      2.0            3.0          3.0  2015   \n",
       "1                36           2.0     11.0            5.0          0.0  2015   \n",
       "2                37           0.0     10.0            4.0          1.0  2015   \n",
       "3                38           0.0     16.0           13.0          0.0  2015   \n",
       "4                39           6.0     34.0           13.0          6.0  2015   \n",
       "\n",
       "   Total Cases Epiweek Week Ending  \n",
       "0          9.0  201535  2015-09-05  \n",
       "1         18.0  201536  2015-09-12  \n",
       "2         15.0  201537  2015-09-19  \n",
       "3         29.0  201538  2015-09-26  \n",
       "4         59.0  201539  2015-10-03  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.to_csv('df_flu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pickle\n",
    "\n",
    "# df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu.pkl\", \"rb\" ))\n",
    "# df_flu_COVID = df_flu[df_flu['Week Ending'] >= pd.to_datetime('2020-03-01')]\n",
    "# df_flu_COVID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_flu_COVID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(df_flu_COVID, open(r\"..\\data\\flu_cases\\df_flu_COVID.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flu_COVID = df_flu_COVID[['Week Ending', 'Total Cases']]\n",
    "# df_flu_COVID = df_flu_COVID.set_index('Week Ending')\n",
    "# df_flu_COVID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(df_flu_COVID, open(r\"..\\data\\flu_cases\\df_flu_COVID_total.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flu = df_flu[['Week Ending', 'Total Cases']]\n",
    "# df_flu = df_flu.set_index('Week Ending')\n",
    "# df_flu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(df_flu, open(r\"..\\data\\flu_cases\\df_flu_total.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flu_pre_COVID = df_flu_pre_COVID[['Week Ending', 'Total Cases']]\n",
    "# df_flu_pre_COVID = df_flu_pre_COVID.set_index('Week Ending')\n",
    "# df_flu_pre_COVID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(df_flu_pre_COVID, open(r\"..\\data\\flu_cases\\df_flu_pre_COVID_total.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu_pre_COVID.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu_COVID.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = df_flu.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_flu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "freq = 'D'\n",
    "df_test['Next Week'] = df_test['Week Ending'] + pd.Timedelta(7, unit=freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.set_index('Week Ending', inplace = True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc['2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc['2015-11-01':'2015-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(columns='Next Week', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = [20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.asfreq('M', method='bfill') # only returns value at the end of the specified frequency if there's a data point faling on that date\n",
    "# bfill fills the null values with the value from the next available time point\n",
    "# ffill fills the null values with the value from the last availabe time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1 = df_flu\n",
    "line2 = df_flu.resample('A').mean()\n",
    "line3 = df_flu.asfreq('A', method='ffill')\n",
    "line4 = df_flu.asfreq('D', method='bfill')\n",
    "plt.plot(line1, alpha = 0.5, linestyle = '-', label = 'input')\n",
    "plt.plot(line2, linestyle = ':', label = 'resample')\n",
    "plt.plot(line3, linestyle = '--', label = 'asfreq')\n",
    "# plt.plot(line4, linestyle = '-.', label = 'asfreq_day')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.shift(1) # moves data points forward one month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flu['t+1'] = df_flu.shift(1)\n",
    "# df_flu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, sharex = True)\n",
    "# apply a frequency to the data\n",
    "df_flu = df_flu.asfreq('W', method='pad')\n",
    "\n",
    "line1, = ax[0].plot(df_flu, label = 'input')\n",
    "line2, = ax[1].plot(df_flu.shift(53), label = 'shift(52)')\n",
    "\n",
    "#legends and annotations\n",
    "local_max = pd.to_datetime('2019-01-01')\n",
    "offset = pd.Timedelta(53, 'W')\n",
    "\n",
    "ax[0].legend(loc=2)\n",
    "# ax[0].get_xticklabels()[4].set(weight='heavy', color='red')\n",
    "ax[0].axvline(local_max, alpha=0.3, color='red')\n",
    "\n",
    "ax[1].legend(loc=2)\n",
    "ax[1].get_xticklabels()[4].set(weight='heavy', color='red')\n",
    "ax[1].axvline(local_max + offset, alpha=0.3, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Average as a Data Preparation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling = df_flu['Total Cases'].rolling(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu['2-week moving average'] = rolling.mean()\n",
    "df_flu['2-week moving std'] = rolling.std()\n",
    "df_flu.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "statistics.mean([18,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_flu.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_total.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling = df_flu['Total Cases'].rolling(4)\n",
    "df_flu['4-week moving average'] = rolling.mean()\n",
    "df_flu['4-week moving std'] = rolling.std()\n",
    "ax = df_flu.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_total.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling = df_flu['Total Cases'].rolling(6)\n",
    "df_flu['6-week moving average'] = rolling.mean()\n",
    "df_flu['6-week moving std'] = rolling.std()\n",
    "ax = df_flu.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_total.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling = df_flu['Total Cases'].rolling(8)\n",
    "df_flu['8-week moving average'] = rolling.mean()\n",
    "df_flu['8-week moving std'] = rolling.std()\n",
    "ax = df_flu.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_total.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Average as Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 2\n",
    "lag1 = df_flu.shift(1)\n",
    "lag2 = df_flu.shift(width-1)\n",
    "window = lag2.rolling(window=width)\n",
    "moving_average = window.mean()\n",
    "df_flu['2-week Moving Average'] = moving_average\n",
    "df_flu['t - 1'] = lag1\n",
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Average as Prediction - 1 week into future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_total.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "X = df_flu['Total Cases']\n",
    "window = 2\n",
    "history = [X[i] for i in range(window)]\n",
    "test = [X[i] for i in range(window, len(X))]\n",
    "predictions = list()\n",
    "\n",
    "# walk forward over time steps in test\n",
    "for t in range(len(test)):\n",
    "    length = len(history)\n",
    "    yhat = mean([history[i] for i in range(length-window, length)])\n",
    "    obs = test[t]\n",
    "    predictions.append(yhat)\n",
    "    history.append(obs)\n",
    "    print(f'predicted={yhat}, actual={obs}')\n",
    "\n",
    "# evaluate\n",
    "MSE = round(mean_squared_error(test, predictions),3)\n",
    "RMSE = round(mean_squared_error(test, predictions, squared=False),3)\n",
    "MAE = round(mean_absolute_error(test, predictions),3)\n",
    "\n",
    "print(f'Test MSE: {MSE}')   # weights large errors more than smaller ones, good for penalizing big mistakes, loses unit because squared\n",
    "print(f'Test RMSE: {RMSE}')  # more interpretable than MSE because avoids losing units. Also sensitive to outliers\n",
    "print(f'Test MAE: {MAE}')   # doesn't penalize outliers as much\n",
    "\n",
    "# can't use MAPE (mean absolute percentage error, because there are zero values in the dataset)\n",
    "\n",
    "\n",
    "# plot\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.show()\n",
    "\n",
    "# zoom plot\n",
    "plt.plot(test[0:52])\n",
    "plt.plot(predictions[0:52], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Average as Prediction - 4 weeks into future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_total.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = df_flu.resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "X = df_flu['Total Cases']\n",
    "window = 2\n",
    "history = [X[i] for i in range(window)]\n",
    "test = [X[i] for i in range(window, len(X))]\n",
    "predictions = list()\n",
    "\n",
    "# walk forward over time steps in test\n",
    "for t in range(len(test)):\n",
    "    length = len(history)\n",
    "    yhat = mean([history[i] for i in range(length-window, length)])\n",
    "    obs = test[t]\n",
    "    predictions.append(yhat)\n",
    "    history.append(obs)\n",
    "    print(f'predicted={yhat}, actual={obs}')\n",
    "\n",
    "# evaluate\n",
    "MSE = round(mean_squared_error(test, predictions),3)\n",
    "RMSE = round(mean_squared_error(test, predictions, squared=False),3)\n",
    "MAE = round(mean_absolute_error(test, predictions),3)\n",
    "\n",
    "print(f'Test MSE: {MSE}')   # weights large errors more than smaller ones, good for penalizing big mistakes, loses unit because squared\n",
    "print(f'Test RMSE: {RMSE}')  # more interpretable than MSE because avoids losing units. Also sensitive to outliers\n",
    "print(f'Test MAE: {MAE}')   # doesn't penalize outliers as much\n",
    "\n",
    "# can't use MAPE (mean absolute percentage error, because there are zero values in the dataset)\n",
    "\n",
    "\n",
    "# plot\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.show()\n",
    "\n",
    "# zoom plot\n",
    "plt.plot(test[0:52])\n",
    "plt.plot(predictions[0:52], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_total.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_flu['Total Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "\n",
    "X = df_flu['Total Cases']\n",
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "print('train_length:', len(train), '\\ntest_lenth:', len(test) )\n",
    "\n",
    "# forecast horizon\n",
    "h = len(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Naive Forecast - Post-COVID\n",
    "Uses the observations from the corresponding season from last period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pysnaive(train_series,seasonal_periods,forecast_horizon):\n",
    "    '''\n",
    "    Python implementation of Seasonal Naive Forecast. \n",
    "    This should work similar to https://otexts.com/fpp2/simple-methods.html\n",
    "    Returns two arrays\n",
    "     > fitted: Values fitted to the training dataset\n",
    "     > fcast: seasonal naive forecast\n",
    "    \n",
    "    Author: Sandeep Pawar\n",
    "    \n",
    "    Date: Apr 9, 2020\n",
    "    \n",
    "    Ver: 1.0\n",
    "    \n",
    "    train_series: Pandas Series\n",
    "        Training Series to be used for forecasting. This should be a valid Pandas Series. \n",
    "        Length of the Training set should be greater than or equal to number of seasonal periods\n",
    "        \n",
    "    Seasonal_periods: int\n",
    "        No of seasonal periods\n",
    "        Yearly=1\n",
    "        Quarterly=4\n",
    "        Monthly=12\n",
    "        Weekly=52\n",
    "        \n",
    "\n",
    "    Forecast_horizon: int\n",
    "        Number of values to forecast into the future\n",
    "    \n",
    "    e.g. \n",
    "    fitted_values = pysnaive(train,12,12)[0]\n",
    "    fcast_values = pysnaive(train,12,12)[1]\n",
    "    '''\n",
    "    \n",
    "    if len(train_series)>= seasonal_periods: #checking if there are enough observations in the training data\n",
    "        \n",
    "        last_season=train_series.iloc[-seasonal_periods:]\n",
    "        \n",
    "        reps=int(np.ceil(forecast_horizon/seasonal_periods))\n",
    "        \n",
    "        fcarray=np.tile(last_season,reps)\n",
    "        \n",
    "        fcast=pd.Series(fcarray[:forecast_horizon])\n",
    "        \n",
    "        fitted = train_series.shift(seasonal_periods)\n",
    "        \n",
    "    else:\n",
    "        fcast=print(\"Length of the trainining set must be greater than number of seasonal periods\") \n",
    "    \n",
    "    return fitted, fcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(test).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted values\n",
    "\n",
    "py_snaive_fit = pysnaive(train,\n",
    "                            seasonal_periods=52,\n",
    "                            forecast_horizon=h)[0]\n",
    "\n",
    "# forecast\n",
    "\n",
    "py_snaive = pysnaive(train,\n",
    "                        seasonal_periods=52,\n",
    "                        forecast_horizon=h)[1]\n",
    "\n",
    "# residuals\n",
    "\n",
    "py_snaive_resid = (train - py_snaive_fit).dropna()\n",
    "\n",
    "\n",
    "# predictions\n",
    "\n",
    "predictions['py_snaive'] = py_snaive.values\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "plt.style.use('seaborn-white')\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.register_matplotlib_converters()\n",
    "df_flu['Total Cases'].plot(figsize=(12,8), style=\"--\", color=\"gray\", legend=True, label=\"Train\")\n",
    "py_snaive_fit.plot(color='g', legend=True, label=\"Snaive_Fitted\")\n",
    "predictions['Total Cases'].plot(linestyle='--', color='r', legend=True, label=\"Test\")\n",
    "predictions['py_snaive'].plot(color='b', legend=True, label='Snaive_forecast');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score:\n",
    "\n",
    "MSE = round(mean_squared_error(train, predictions),3)\n",
    "RMSE = round(mean_squared_error(train, predictions, squared=False),3)\n",
    "MAE = round(mean_absolute_error(train, predictions),3)\n",
    "\n",
    "print(f'train MSE: {MSE}')   # weights large errors more than smaller ones, good for penalizing big mistakes, loses unit because squared\n",
    "print(f'train RMSE: {RMSE}')  # more interpretable than MSE because avoids losing units. Also sensitive to outliers\n",
    "print(f'train MAE: {MAE}')   # doesn't penalize outliers as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test score:\n",
    "\n",
    "MSE = round(mean_squared_error(predictions['Total Cases'], predictions['py_snaive']),3)\n",
    "RMSE = round(mean_squared_error(predictions['Total Cases'], predictions['py_snaive'], squared=False),3)\n",
    "MAE = round(mean_absolute_error(predictions['Total Cases'], predictions['py_snaive']),3)\n",
    "\n",
    "print(f'Test MSE: {MSE}')   # weights large errors more than smaller ones, good for penalizing big mistakes, loses unit because squared\n",
    "print(f'Test RMSE: {RMSE}')  # more interpretable than MSE because avoids losing units. Also sensitive to outliers\n",
    "print(f'Test MAE: {MAE}')   # doesn't penalize outliers as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "plt.style.use('seaborn-white')\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "\n",
    "#statistics libraries\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "from scipy.stats import anderson\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import month_plot, seasonal_plot, plot_acf, plot_pacf, quarter_plot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing, SimpleExpSmoothing\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox as ljung\n",
    "from statsmodels.tsa.statespace.tools import diff as diff\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import pmdarima as pm\n",
    "from pmdarima import ARIMA, auto_arima\n",
    "from scipy import signal\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import jarque_bera as jb\n",
    "from itertools import combinations\n",
    "\n",
    "import fbprophet as Prophet\n",
    "\n",
    "\n",
    "#library to use R in Python \n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    " \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import month_plot, seasonal_plot, plot_acf, plot_pacf, quarter_plot\n",
    "\n",
    "def residcheck(residuals, lags):\n",
    "    \"\"\"\n",
    "    Function to check if the residuals are white noise. Ideally the residuals should be uncorrelated, zero mean, \n",
    "    constant variance and normally distributed. First two are must, while last two are good to have. \n",
    "    If the first two are not met, we have not fully captured the information from the data for prediction. \n",
    "    Consider different model and/or add exogenous variable. \n",
    "    \n",
    "    If Ljung Box test shows p> 0.05, the residuals as a group are white noise. Some lags might still be significant. \n",
    "    \n",
    "    Lags should be min(2*seasonal_period, T/5)\n",
    "    \n",
    "    plots from: https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "    \n",
    "    \"\"\"\n",
    "    resid_mean = np.mean(residuals)\n",
    "    lj_p_val = np.mean(ljung(x=residuals, lags=lags)[1])\n",
    "    norm_p_val =  jb(residuals)[1]\n",
    "    adfuller_p = adfuller(residuals)[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    layout = (2, 2)\n",
    "    ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2);\n",
    "    acf_ax = plt.subplot2grid(layout, (1, 0));\n",
    "    kde_ax = plt.subplot2grid(layout, (1, 1));\n",
    "\n",
    "    residuals.plot(ax=ts_ax)\n",
    "    plot_acf(residuals, lags=lags, ax=acf_ax);\n",
    "    sns.kdeplot(residuals);\n",
    "    #[ax.set_xlim(1.5) for ax in [acf_ax, kde_ax]]\n",
    "    sns.despine()\n",
    "    plt.tight_layout();\n",
    "    \n",
    "    print(\"** Mean of the residuals: \", np.around(resid_mean,2))\n",
    "    \n",
    "    print(\"\\n** Ljung Box Test, p-value:\", np.around(lj_p_val,3), \"(>0.05, Uncorrelated)\" if (lj_p_val > 0.05) else \"(<0.05, Correlated)\")\n",
    "    \n",
    "    print(\"\\n** Jarque Bera Normality Test, p_value:\", np.around(norm_p_val,3), \"(>0.05, Normal)\" if (norm_p_val>0.05) else \"(<0.05, Not-normal)\")\n",
    "    \n",
    "    print(\"\\n** AD Fuller, p_value:\", np.around(adfuller_p,3), \"(>0.05, Non-stationary)\" if (adfuller_p > 0.05) else \"(<0.05, Stationary)\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return ts_ax, acf_ax, kde_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(len(df_flu)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_period = 52\n",
    "T = len(df_flu)\n",
    "lags = min(2*seasonal_period, round(T/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residcheck(py_snaive_resid,lags=lags);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Naive Forecast - Pre-COVID\n",
    "Uses the observations from the corresponding season from last period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu_pre_COVID = pickle.load(open(r\"..\\data\\flu_cases\\df_flu_pre_COVID_total.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu_pre_COVID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "\n",
    "X = df_flu_pre_COVID['Total Cases']\n",
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "print('train_length:', len(train), '\\ntest_lenth:', len(test) )\n",
    "\n",
    "# forecast horizon\n",
    "h = len(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pysnaive(train_series,seasonal_periods,forecast_horizon):\n",
    "    '''\n",
    "    Python implementation of Seasonal Naive Forecast. \n",
    "    This should work similar to https://otexts.com/fpp2/simple-methods.html\n",
    "    Returns two arrays\n",
    "     > fitted: Values fitted to the training dataset\n",
    "     > fcast: seasonal naive forecast\n",
    "    \n",
    "    Author: Sandeep Pawar\n",
    "    \n",
    "    Date: Apr 9, 2020\n",
    "    \n",
    "    Ver: 1.0\n",
    "    \n",
    "    train_series: Pandas Series\n",
    "        Training Series to be used for forecasting. This should be a valid Pandas Series. \n",
    "        Length of the Training set should be greater than or equal to number of seasonal periods\n",
    "        \n",
    "    Seasonal_periods: int\n",
    "        No of seasonal periods\n",
    "        Yearly=1\n",
    "        Quarterly=4\n",
    "        Monthly=12\n",
    "        Weekly=52\n",
    "        \n",
    "\n",
    "    Forecast_horizon: int\n",
    "        Number of values to forecast into the future\n",
    "    \n",
    "    e.g. \n",
    "    fitted_values = pysnaive(train,12,12)[0]\n",
    "    fcast_values = pysnaive(train,12,12)[1]\n",
    "    '''\n",
    "    \n",
    "    if len(train_series)>= seasonal_periods: #checking if there are enough observations in the training data\n",
    "        \n",
    "        last_season=train_series.iloc[-seasonal_periods:]\n",
    "        \n",
    "        reps=int(np.ceil(forecast_horizon/seasonal_periods))\n",
    "        \n",
    "        fcarray=np.tile(last_season,reps)\n",
    "        \n",
    "        fcast=pd.Series(fcarray[:forecast_horizon])\n",
    "        \n",
    "        fitted = train_series.shift(seasonal_periods)\n",
    "        \n",
    "    else:\n",
    "        fcast=print(\"Length of the trainining set must be greater than number of seasonal periods\") \n",
    "    \n",
    "    return fitted, fcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(test).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted values\n",
    "\n",
    "py_snaive_fit = pysnaive(train,\n",
    "                            seasonal_periods=52,\n",
    "                            forecast_horizon=h)[0]\n",
    "\n",
    "# forecast\n",
    "\n",
    "py_snaive = pysnaive(train,\n",
    "                        seasonal_periods=52,\n",
    "                        forecast_horizon=h)[1]\n",
    "\n",
    "# residuals\n",
    "\n",
    "py_snaive_resid = (train - py_snaive_fit).dropna()\n",
    "\n",
    "\n",
    "# predictions\n",
    "\n",
    "predictions['py_snaive'] = py_snaive.values\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "plt.style.use('seaborn-white')\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.register_matplotlib_converters()\n",
    "df_flu_pre_COVID['Total Cases'].plot(figsize=(12,8), style=\"--\", color=\"gray\", legend=True, label=\"Train\")\n",
    "py_snaive_fit.plot(color='g', legend=True, label=\"Snaive_Fitted\")\n",
    "predictions['Total Cases'].plot(linestyle='--', color='r', legend=True, label=\"Test\")\n",
    "predictions['py_snaive'].plot(color='b', legend=True, label='Snaive_forecast');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training score:\n",
    "\n",
    "# MSE = round(mean_squared_error(train, predictions),3)\n",
    "# RMSE = round(mean_squared_error(train, predictions, squared=False),3)\n",
    "# MAE = round(mean_absolute_error(train, predictions),3)\n",
    "\n",
    "# print(f'train MSE: {MSE}')   # weights large errors more than smaller ones, good for penalizing big mistakes, loses unit because squared\n",
    "# print(f'train RMSE: {RMSE}')  # more interpretable than MSE because avoids losing units. Also sensitive to outliers\n",
    "# print(f'train MAE: {MAE}')   # doesn't penalize outliers as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test score:\n",
    "\n",
    "MSE = round(mean_squared_error(predictions['Total Cases'], predictions['py_snaive']),3)\n",
    "RMSE = round(mean_squared_error(predictions['Total Cases'], predictions['py_snaive'], squared=False),3)\n",
    "MAE = round(mean_absolute_error(predictions['Total Cases'], predictions['py_snaive']),3)\n",
    "\n",
    "print(f'Test MSE: {MSE}')   # weights large errors more than smaller ones, good for penalizing big mistakes, loses unit because squared\n",
    "print(f'Test RMSE: {RMSE}')  # more interpretable than MSE because avoids losing units. Also sensitive to outliers\n",
    "print(f'Test MAE: {MAE}')   # doesn't penalize outliers as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "plt.style.use('seaborn-white')\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "\n",
    "#statistics libraries\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "from scipy.stats import anderson\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import month_plot, seasonal_plot, plot_acf, plot_pacf, quarter_plot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing, SimpleExpSmoothing\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox as ljung\n",
    "from statsmodels.tsa.statespace.tools import diff as diff\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import pmdarima as pm\n",
    "from pmdarima import ARIMA, auto_arima\n",
    "from scipy import signal\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import jarque_bera as jb\n",
    "from itertools import combinations\n",
    "\n",
    "import fbprophet as Prophet\n",
    "\n",
    "\n",
    "#library to use R in Python \n",
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    " \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import month_plot, seasonal_plot, plot_acf, plot_pacf, quarter_plot\n",
    "\n",
    "def residcheck(residuals, lags):\n",
    "    \"\"\"\n",
    "    Function to check if the residuals are white noise. Ideally the residuals should be uncorrelated, zero mean, \n",
    "    constant variance and normally distributed. First two are must, while last two are good to have. \n",
    "    If the first two are not met, we have not fully captured the information from the data for prediction. \n",
    "    Consider different model and/or add exogenous variable. \n",
    "    \n",
    "    If Ljung Box test shows p> 0.05, the residuals as a group are white noise. Some lags might still be significant. \n",
    "    \n",
    "    Lags should be min(2*seasonal_period, T/5)\n",
    "    \n",
    "    plots from: https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "    \n",
    "    \"\"\"\n",
    "    resid_mean = np.mean(residuals)\n",
    "    lj_p_val = np.mean(ljung(x=residuals, lags=lags)[1])\n",
    "    norm_p_val =  jb(residuals)[1]\n",
    "    adfuller_p = adfuller(residuals)[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    layout = (2, 2)\n",
    "    ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2);\n",
    "    acf_ax = plt.subplot2grid(layout, (1, 0));\n",
    "    kde_ax = plt.subplot2grid(layout, (1, 1));\n",
    "\n",
    "    residuals.plot(ax=ts_ax)\n",
    "    plot_acf(residuals, lags=lags, ax=acf_ax);\n",
    "    sns.kdeplot(residuals);\n",
    "    #[ax.set_xlim(1.5) for ax in [acf_ax, kde_ax]]\n",
    "    sns.despine()\n",
    "    plt.tight_layout();\n",
    "    \n",
    "    print(\"** Mean of the residuals: \", np.around(resid_mean,2))\n",
    "    \n",
    "    print(\"\\n** Ljung Box Test, p-value:\", np.around(lj_p_val,3), \"(>0.05, Uncorrelated)\" if (lj_p_val > 0.05) else \"(<0.05, Correlated)\")\n",
    "    \n",
    "    print(\"\\n** Jarque Bera Normality Test, p_value:\", np.around(norm_p_val,3), \"(>0.05, Normal)\" if (norm_p_val>0.05) else \"(<0.05, Not-normal)\")\n",
    "    \n",
    "    print(\"\\n** AD Fuller, p_value:\", np.around(adfuller_p,3), \"(>0.05, Non-stationary)\" if (adfuller_p > 0.05) else \"(<0.05, Stationary)\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return ts_ax, acf_ax, kde_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(len(df_flu)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_period = 52\n",
    "T = len(df_flu)\n",
    "lags = min(2*seasonal_period, round(T/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residcheck(py_snaive_resid,lags=lags);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline / level = average value\n",
    "\n",
    "a = round(df_flu_pre_COVID['Total Cases'].mean())\n",
    "b = round(df_flu_COVID['Total Cases'].mean())\n",
    "c = round(df_flu['Total Cases'].mean())\n",
    "\n",
    "print(f'Baseline flu level from September 2015 to March 2020 was approximately {a} laboratory-confirmed cases per week.')\n",
    "print(f'Baseline flu level from March 2020 to to present was approximately {b} laboratory-confirmed cases per week.')\n",
    "print(f'Baseline flu level from September 2015 to to present was approximately {c} laboratory-confirmed cases per week.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics\n",
    "df_flu_pre_COVID.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu_COVID.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
